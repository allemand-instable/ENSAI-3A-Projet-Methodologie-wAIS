\twocolumn[
\begin{@twocolumnfalse}
\section{Glossary}
\begin{table}[t]
\begin{tabular}{|c|l|l}
\cline{1-2}
word                          & \multicolumn{1}{c|}{explanation}                                                                                                                                                                                                                                                                   &  \\ \cline{1-2}
Kullback-Leibler Divergence   & \begin{tabular}[c]{@{}l@{}} [Insert the mathmatical formula: The Kullback-Leibler Divergence measures the proximity of two distribution functions q and f, i.e. how similar they are, assuming f is the distribution from which the the sample $x_i$ was generated from. A function which measures how similar two given distributions are \\ - similar to a metric\end{tabular}                                                                                                                                                                 &  \\ \cline{1-2}
loss function                 & the loss function penalizes the deviations of an estimate from the true value it is trying to approximate in a prespecified way                                                                                                                                                                                                                                      &  \\ \cline{1-2}
normalization constant        & \begin{tabular}[c]{@{}l@{}}constant we want to divide the integral \\ \\ by in order to make it equal to one and \\ \\ thus making it a probability density function\end{tabular}                                                                                                                  &  \\ \cline{1-2}
stochastic                    & \begin{tabular}[c]{@{}l@{}}process or method which underlies uncertainty and thus relies on \\ \\ probabilities and random events\end{tabular}                                                                                                                                                                                    &  \\ \cline{1-2}
sample                        & collection of values generated from a distribution                                                                                                                                                                                                                                                 &  \\ \cline{1-2}
sampling policy               & \begin{tabular}[c]{@{}l@{}}probability density function from which the \\ \\ samples will be drawn from during the algorithm\end{tabular}                                                                                                                                                          &  \\ \cline{1-2}
gradient                      & \begin{tabular}[c]{@{}l@{}}vector representing the derivative of a function : \\ \\ it represents the direction of steepest slope of a function \\ \\ \end{tabular}                                                                                                                              &  \\ \cline{1-2}
likelihood                    & \begin{tabular}[c]{@{}l@{}}A function which outputs a number representing the \\ \\ probability of jointly observing the data under \\ \\ a certain probability function.\\ \\ The higher the likelihood for a given distribution $q$, \\ \\ the more likely the data has been sampled from $q$. The likelihood can also be understood as a measure of how plausible observing data is under a given distribution. \end{tabular} &  \\ \cline{1-2}
distribution density function & \begin{tabular}[c]{@{}l@{}}function which characterizes the uncertainty that underlies a random variable. \\ \\ it dictates the patterns in which data appears \\ \\ and hence provides insights into how spread out it is. \end{tabular}                                                                                                                             &  \\ \cline{1-2}
Monte Carlo                   & \begin{tabular}[c]{@{}l@{}}a monte carlo method is a method involving \\ \\ probabilities to solve a deterministic problem approximatively\end{tabular}                                                                                                                                            &  \\ \cline{1-2}
expectation                   &                                                                                                                                                                                                                                                                                                    &  \\ \cline{1-2}
\end{tabular}
\end{table}
\end{@twocolumnfalse}
]

