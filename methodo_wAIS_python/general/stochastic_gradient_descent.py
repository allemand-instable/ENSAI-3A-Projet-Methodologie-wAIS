import numpy as np
from copy import deepcopy
# typing
from typing import Callable, List, Literal, Optional, Tuple
from numpy.typing import NDArray
from custom_typing.custom_types import ImportanceSamplingGradientEstimation
# random
from random import randint
import numpy.random as nprd
from benchmark.combine_error_graphs import BenchmarkGraph
from benchmark.show_error_graph import show_error_graph
# My Modules
from distribution_family.distribution_family import DistributionFamily
# Debug
from utils.log import logstr
from logging import info, debug, warn, error
from utils.print_array_as_vector import get_vector_str
# Kullback Leibler related functions
from general.parameters_initialisation import benchmark_init, initialisation


def cond_n_de_suite__update_state(cond, state : list[bool]) -> list[bool]:
    """lors du Gradient Ascent, on veut arrÃªter les itÃ©rations si on remarque que la norme du gradient est en dessous d'un seuil | pour s'assurer de ne pas Ãªtre dans un minimum local non global, on regarde si cette condition est vÃ©rifiÃ©e plusieurs fois d'affilÃ©e"""
    # true and false in state
    if all(state):
        new_state = state
    else:
        if cond is True:
            first_false = state.index(False)
            new_state = deepcopy(state)
            new_state[first_false] = True
        else:
            new_state = [False for k in range(len(state))]
    # all true
    return new_state

def get_X_sampled_from_uniform(adaptive,q_t, nb_stochastic_choice, nb_drawn_samples, X, given_X) -> List[float] | None:
    if not given_X :
    # Adaptive â‡’ we sample from the new distribution at each iteration
        if adaptive :
            new_sample : list | None = q_t.sample(nb_drawn_samples)
            # la mÃ©thode sample peut retourner un None en cas de problÃ¨me, on doit gÃ©rer le cas
            if new_sample is None :
                raise ValueError(f"could not sample from q_t \n(params = {q_t.parameters})\nnew_sample = None")
            else :
                X = new_sample + X
    else :
        X = given_X
    # non stochastic gradient ascent â‡’ use all X
    if nb_stochastic_choice == nb_drawn_samples :
        X_sampled_from_uniform = X
    # stochastic gradient descent â‡’ use a subset of X
    else :
        obs_tirÃ©es = nprd.choice(range(len(X)), nb_stochastic_choice, replace=False)
        X_sampled_from_uniform = [  X[i] for i in obs_tirÃ©es  ]
        return X_sampled_from_uniform



def gradient_descent(
                                        # distributions
                                        f_target : DistributionFamily ,
                                        q_init : DistributionFamily , 
                                        # function to be computed
                                        compute_grad_L_importance_sampling : ImportanceSamplingGradientEstimation,
                                        # stochastic part
                                        nb_drawn_samples : Optional[int], 
                                        nb_stochastic_choice : Optional[int], 
                                        # gradient ascent parameters
                                        step : float, 
                                        Î¸_0 : Optional[NDArray] = None, 
                                        É› : float = 1e-6, 
                                        iter_limit = 100, 
                                        # other parameters
                                        method : Literal["descent"] | Literal["ascent"] = "descent",
                                        update_Î· : Callable = lambda x : x,
                                        benchmark : bool = False, 
                                        max_L_gradient_norm : int | float = np.Infinity,
                                        adaptive : bool = False,
                                        show_benchmark_graph : bool = False,
                                        # specific sub component of parameter of interest
                                        param_composante : Optional[int] = None,
                                        given_X : Optional[List[float]] = None,
                                        print_theta : bool = False
                                    ) -> Tuple[NDArray, Optional[BenchmarkGraph]]:
    """effectue une stochastic gradient ascent pour le problÃ¨me d'optimisation de Î¸ suivant le critÃ¨re de la vraissemblance de Kullback-Leibler
        
    f_target                        â€” target density
                                        â¤ va Ãªtre utilisÃ©e pour la comparaison avec q dans la maximisation de la vraissemblance de Kullback-Leibler
                                        
                                        L(Î¸) = - KL( f || q )
    
    q_init                          â€” original sampling policy : q(ğ‘¥, Î¸)
    
                                                        parametric family of sampling policies / distributions
                                                        given as a (lambda) function of ğ‘¥, Î¸ âˆˆ ğ˜Ÿ Ã— Î˜

                                                        q = lambda x,Î¸ : np.exp( - (x-Î¸[0])**2 / (2*Î¸[1]) )/(np.sqrt(2*np.pi*Î¸[1]))
                                                        gives a normal law density

                                    â¤ va Ãªtre modifiÃ©e Ã  chaque itÃ©ration
    
    
    compute_grad_L_importance_sampling  â€”

    update_Î·                        â€” how the step should be updated
                                            â†ª defaults to : constant
    
    nb_drawn_samples (N)            â€” Nombre de samples tirÃ©s par la distribution q Ã  chaque itÃ©ration
    
    nb_stochastic_choice (ğ›¾)        â€” nombre d'observations Ã  tirer alÃ©atoirement
    
    step (Î·_0)                      â€” initialisation du pas
    
    Î¸_0                             â€” initialisation des paramÃ¨tres
    
    É›                               â€” threshold pour la norme du gradient
    
    iter_limit                      â€” nombre d'itÃ©rations max du gradient descent avant l'arrÃªt

    benchmark                       â€” if True, produces error graphs values as dicts
    
    max_L_gradient_norm             â€” safety coefficient : if â€– ğ›L â€– > ğœ¶ â€– Î¸_t â€–
                                        â†ª we use ğœ¶ Ã— (ğ›L / â€– ğ›L â€–)
                                        â†ª Default : unbound         [ np.Infinity ]
                                        
    adaptive                        â€” sample X = (ğ‘¥áµ¢)â‚,â‚™
                                            â†ª Ã  partir de q_init    [ False ]
                                            
                                            â†ª Ã  partir de qâ‚œ        [ True  ]
                                            
    show_benchmark_graph            â€” shows graphs at the end of the procedure
    
    param_composante                â€” only applies SGD to a subcomponent of the parameters
                                            â†ª example : Normal ğ’©(Î¼, ÏƒÂ²)
                                                param_composante = 0 â‡’ only applies SGD to Î¼  (known variance)
                                                param_composante = 1 â‡’ only applies SGD to ÏƒÂ² (known mean)
                                            
    """
    
    """Initialisation"""
    Î·_t, Î¸_t, norm_grad_L, X, q_t, benchmark_graph, state = initialisation(q_init, É›, Î¸_0, step, benchmark)
    
    target, theta_init = benchmark_init(benchmark_graph, f_target, Î¸_t)
    
    # How samples are being drawn depending on whether importance sampling is from a fixed distribution or adaptive
    if not given_X :
        X_sampled_from_uniform = []
        if not adaptive :
            X = q_init.sample(nb_drawn_samples)
            if X is None :
                X = []
                raise ValueError("generated sample is None !")
        else :
            X = []
    else :
        X = given_X
    
    
    
    """MAIN LOOP"""
    for counter in range(iter_limit):
        
        # si on a atteint l'objectif (on est dans un minimum local et on espÃ¨re global) on peut arrÃªter els itÃ©rations
        if all(cond_n_de_suite__update_state(norm_grad_L <= É›, state)):
            debug(logstr(f"norm_grad_L = {norm_grad_L}"))
            break
        
        X_sampled_from_uniform = get_X_sampled_from_uniform(adaptive,q_t, nb_stochastic_choice, nb_drawn_samples, X, given_X)
        if X_sampled_from_uniform is None :
            raise ValueError("X_sampled_from_uniform is None")
        
        # computation of an estimator of ğ›L
        if adaptive :
            grad_L_estimator = compute_grad_L_importance_sampling(f_target, q_t, q_t,
                                                        Î¸_t, 
                                                        # nb_stochastic_choice,
                                                        max_L_gradient_norm, 
                                                        X_sampled_from_uniform,
                                                        param_composante)
        else :
            grad_L_estimator = compute_grad_L_importance_sampling(f_target, q_t, q_init,
                                                        Î¸_t, 
                                                        # nb_stochastic_choice,
                                                        max_L_gradient_norm, 
                                                        X_sampled_from_uniform,
                                                        param_composante)
        # computation of â€–ğ›Lâ€–
        norm_grad_L = np.linalg.norm(grad_L_estimator)
        
        # gradient descent
        if method == "descent" :
            Î¸_t = Î¸_t - Î·_t * grad_L_estimator
        # gradient ascent
        elif method == "ascent":
            Î¸_t = Î¸_t + Î·_t * grad_L_estimator
        else :
            raise ValueError(f"the method should be either 'descent' or 'ascent' | here : {method}")
        
        """â€”â€”â€” Parameters update â€”â€”â€”"""
        q_t.update_parameters(Î¸_t)
        Î·_t = update_Î·(Î·_t)
        
        #printing every 20 iterations in the console
        if print_theta :
            if counter % 20 == 0 :
                str_theta = f"Î¸_{counter} = {Î¸_t}"
                print(str_theta)
                debug(logstr(str_theta))
                debug(logstr(f"Î·_t+1 = {Î·_t}"))
                # todo : one may also implement here a save of the parameter found every 20 iterations, or even better choose a number of iterations before a checkmark (...)
        
        """â€”â€”â€” Benchmarking â€”â€”â€”"""
        # if we desire to benchmark : we build the error graph
        if benchmark_graph is not None :
            #           X AXIS
            benchmark_graph[0].append(counter+1)
            #? adding the likelihood graph 
            # benchmark_graph[len(Î¸_t)+1].append(compute_likelihood(f_target=f_target, q_t = q, theta_t=Î¸_t, q_importance_sampling= q_init, X_sampled_from_uniform = X_sampled_from_uniform))
            
            #           Y AXIS
            for k in range(len(Î¸_t)) :
                # we add the relative error between Î¸_t and Î¸_target
                d_k = np.abs((Î¸_t[k] - target[k])/(target[k] + 1e-4))
                #####################################################
                benchmark_graph[1+k].append(d_k)
    # Ã  la fin on plot le graphe des erreurs
    if (benchmark_graph is not None) and (show_benchmark_graph is True) :
        show_error_graph(last_Î¸_t = Î¸_t, 
                         Î¸_target = target, 
                         Î¸_init = theta_init,
                         benchmark_graph = benchmark_graph,
                         # subtitle
                         nb_drawn_samples = len(X_sampled_from_uniform), 
                         nb_stochastic_choice = nb_stochastic_choice, 
                         step = step, 
                         max_L_gradient_norm= max_L_gradient_norm
                         )        
    if benchmark :
        return Î¸_t, benchmark_graph
    else :
        return Î¸_t, None


