import numpy as np
from typing import Any, Callable, Optional
from numpy.typing import NDArray

from utils.log import logstr
from logging import info, debug, warn, error, critical

from numpy.typing import ArrayLike
from typing import Protocol, Union

vector_or_scalar = NDArray | float

# type hinting
class MultivariateFunction_to_R(Protocol):
    """
    function defined by the relation y = f( ğ‘¥áµ¢ )â‚,â‚™
    
    i.e
    
        Î  â„á´¸áµ‰â¿â½Ë£-â±â¾ âŸ¶   â„
    f : ( ğ‘¥áµ¢ )â‚,â‚™   âŸ¼   y
    """
    def __call__(self, *float_args : NDArray[np.float64] ) -> float: ...



def gradient_selon(arg_num : int ,f : MultivariateFunction_to_R, *args ,h = 1e-7, composante : Optional[int] = None) -> NDArray:
    """renvoie le gradient d'une fonction multivariÃ©e f(... ğ‘¥áµ¢ ...)â‚,â‚™ selon  ğ‘¥_{arg_num}  Ã©valuÃ© en les arguments de f (*args)  |   oÃ¹ ğ‘¥áµ¢ âˆˆ â„^p
    
    si composante = ğ‘˜   âŸ¶   renvoie : [ğ›_Î¸â‚–]f(x) = [ 0 , ..., [ğœ•_Î¸â‚–]f(x) , ... , 0 ] âˆˆ â„^p

    Args:
        arg_num (int): starts at 1
        
        f (function): f :   R x R^p âŸ¶   R
                            (x , Î˜)  âŸ¼   f(x , Î˜)
        h (int, optional): finesse de la dÃ©rivÃ©e. Defaults to 1.
                            doit tendre vers 0 (h â‰ˆ 0)
        
        composante (int, optional) : [ğ›_Î¸]f(x) â‡’ [ğ›_Î¸_composante]f(x)
                                     Î¸ = [ Î¸â‚ , Î¸â‚‚ , ... , Î¸â‚š ]
                                     
                                     [ğ›_Î¸]f(x) = [ [ğœ•_Î¸â‚]f(x) , [ğœ•_Î¸â‚‚]f(x) , ... , [ğœ•_Î¸â‚š]f(x) ]
                                     
                                     va donc renvoyer : [ğ›_Î¸_composante]f(x) = [ 0 , ..., [ğœ•_Î¸câ‚’â‚˜â‚šâ‚’â‚›â‚â‚™â‚œâ‚‘]f(x) , ... , 0 ]

    Returns:


        for f(u,v,w) :
        u vector len p
        v vector len q
        w vector len r
        
        gradient_selon(1, f)
        [ [âˆ‚f/âˆ‚u_1](x) ... [âˆ‚f/âˆ‚u_p](x) ]   âˆˆ â„^p
        
        gradient_selon(2, f)
        [ [âˆ‚f/âˆ‚v_1](x) ... [âˆ‚f/âˆ‚v_q](x) ]   âˆˆ â„^q
        
        gradient_selon(3, f)
        [ [âˆ‚f/âˆ‚w_1](x) ... [âˆ‚f/âˆ‚w_r](x) ]   âˆˆ â„^r
        
        gradient_selon(3, f, composante = 2)
        = [ 0  [âˆ‚f/âˆ‚w_2](x)  0  ...  0 ]    âˆˆ â„^r

    """
    debug(logstr(f"Params :\n\narg_num = {arg_num}\nf = {f}\n\nargs = {args} âˆˆ {[type(obj) for obj in args]}"))
    # index
    index = arg_num-1
    # au cas oÃ¹ quelqu'un donne en argument un float
    argument_differencie : np.ndarray = np.array(args[index])
    #                                   on s'assure que on a bien un vecteur numpy
    #                                   si il l'est dÃ©jÃ , il le reste
    #                                   sinon il est transformÃ© en ndarray ( notamment si c'est une liste )
    # dimension du vecteur diffÃ©rentiÃ© [rÃ©utilisÃ© un peu partout aprÃ¨s]
    p = argument_differencie.size
    #
    gradient = np.zeros(p)
    # calcul du gradient
    # we compute each partial derivative
    # faire selon toutes les composantes du vecteur selon lequel on effectue le gradient
    if composante is None :
        for composante_index in range(p):
            # (u,v,w, ...)
            # on dÃ©cide de modifier w, un vecteur de longueur p
            H = np.zeros(shape=p)
            # on ajoute h Ã  une des composantes de w
            # ici : composante_index dans [1,p]
            H[composante_index] = h
            theta_plus_h = argument_differencie + H
            # on renvoie (u, v, w', ...)
            # si la composante modifiÃ© Ã©tait w
            new_args = get_new_args(args, index, theta_plus_h)
            # calcul approchÃ© du gradient de f(u,v,w,...) selon w
            gradient_composante = (f(*new_args) - f(*args))/h
            # grad_w f(u,v,w,...) 
            gradient[composante_index] = gradient_composante
    
    # en sÃ©lectionnant une composante particuliÃ¨re du vecteur selon lequel on effectue le gradient
    else :
        # (u,v,w, ...)
        # on dÃ©cide de modifier w, un vecteur de longueur p
        H = np.zeros(shape=p)
        # on ajoute h Ã  la composante numÃ©ro [composante] de w
        H[composante] = h
        theta_plus_h = argument_differencie + H
        # on renvoie (u, v, w', ...)
        # si la composante modifiÃ© Ã©tait w
        new_args = get_new_args(args, index, theta_plus_h)
        # calcul approchÃ© du gradient de f(u,v,w,...) selon w
        gradient_composante = (f(*new_args) - f(*args))/h
        # grad_w f(u,v,w,...) 
        gradient[composante] = gradient_composante    
    debug(logstr(f"âˆ‡f = {gradient}\n"))
    return(gradient)


def get_new_args(args, index, modified_vec):
    """donnÃ© une liste de vecteurs (potentiellement de dimensions diffÃ©rentes) 
    
    - args = (ğ‘¥áµ¢)â‚,â‚™
    - index = ğ‘˜
    - modified_vec = âƒ—u
    
    ie avec un vec initial : [ ğ‘¥â‚, ... , ğ‘¥â‚– , ğ‘¥â‚–â‚Šâ‚, ... ğ‘¥â‚™  ]
                                         â†“
    retourne le vecteur    : [ ğ‘¥â‚, ... , âƒ—u , ğ‘¥â‚–â‚Šâ‚, ... ğ‘¥â‚™   ]
    """
    # si c'est le premier vecteur que l'on remplace, il suffit d'ajouter les autres aprÃ¨s
    if index == 0 :
        args_copy = list(args)
        args_copy.pop(0)
        res = [modified_vec] +  args_copy
    # sinon il faut concatÃ©ner dans le bon ordre : ceux avant, la modif, ceux aprÃ¨s
    else :
        before = [args[k] for k in range(index)]
        after = [args[(index+1) + k] for k in range(len(args)-(index+1))]
        res = before + [modified_vec] + after
    return res
