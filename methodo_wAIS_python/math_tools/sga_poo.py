from math_tools.gradient import gradient_selon
import numpy as np
from typing import Optional
import numpy.random as nprd
from math_tools.distribution_family import DistributionFamily
from numpy.typing import ArrayLike, NDArray
from utils.log import logstr
from logging import info, debug, warn, error
from utils.print_array_as_vector import get_vector_str
from copy import deepcopy
import time
from typing import Tuple
import plotly.express as plx
from plotly.subplots import make_subplots
import plotly.graph_objects as plgo

class SGA_KullbackLeibler_Likelihood():
    def __init__(self, 
                 f : DistributionFamily ,
                 q : DistributionFamily , 
                 nb_drawn_samples : int, 
                 ğ›¾ : int, 
                 Î·_0 : float, 
                 Î¸_0 : Optional[ArrayLike] = None, 
                 É› : float = - np.inf, 
                 iter_limit : int = 100, 
                 Î·_update_method : str = "fixed",
                 benchmark : bool = False) -> None:
        """effectue une stochastic gradient ascent pour le problÃ¨me d'optimisation de Î¸ suivant le critÃ¨re de la vraissemblance de Kullback-Leibler
            
        f           â€” target density
                        â¤ va Ãªtre utilisÃ©e pour la comparaison avec q dans la maximisation de la vraissemblance de Kullback-Leibler
                        
                        L(Î¸) = - KL( f || q )
        
        q           â€” original sampling policy : q(ğ‘¥, Î¸)
        
                                        parametric family of sampling policies / distributions
                                        given as a (lambda) function of ğ‘¥, Î¸ âˆˆ ğ˜Ÿ Ã— Î˜

                                        q = lambda x,Î¸ : np.exp( - (x-Î¸[0])**2 / (2*Î¸[1]) )/(np.sqrt(2*np.pi*Î¸[1]))
                                        gives a normal law density

                    â¤ va Ãªtre modifiÃ©e Ã  chaque itÃ©ration
        
        
        N           â€” Nombre de samples tirÃ©s par la distribution q Ã  chaque itÃ©ration
        
        ğ›¾           â€” nombre d'observations Ã  tirer alÃ©atoirement
        
        Î·_0         â€” initialisation du pas
        
        Î¸_0         â€” initialisation des paramÃ¨tres
        
        É›           â€” threshold pour la norme du gradient
        
        iter_limit  - nombre d'itÃ©rations max du gradient descent avant l'arrÃªt
        
        """

        # hyper paramÃ¨tres
        
        self.nb_drawn_samples = nb_drawn_samples    # nb_drawn_samples
        self.ğ›¾ = ğ›¾                                  # learning_rate
        self.Î·_0 = Î·_0                              # initialisation du pas
        self.É› = É›                                  # norm threshold
        self.iter_limit = iter_limit                #


        #   â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”     Ã‰viter explosion du gradient        â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        self.norm_safety_coefficient = np.Inf
        
        # update specifications
        self.Î·_update_method = Î·_update_method      # faÃ§on d'update le pas

        # paramÃ¨tres
        self.f = f                                  # target density
        
        # gÃ©rer les formats de Î¸_0
        if Î¸_0 is None :
            # non spÃ©cifiÃ© â†’ prendre les paramÃ¨tres de qâ‚€
            self.Î¸_0 = q.parameters_list()     # initialisation des params de q
        elif type(Î¸_0) in [list, NDArray] :
            # si c'est une liste ou une ndarray
            # on s'assure que c'est au format numpy
            self.Î¸_0 = np.array(Î¸_0)
        else :
            # sinon on connait pas
            raise TypeError(f"mauvais type de Î¸_0 : {type(Î¸_0)}\ntype attendu : [int, NDArray, ...]")
        
        
        
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” #
        #                                 WORKING VAR                                       #
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” #
                
        # initialisation des working vars
        self.Î¸_t : NDArray = np.array(deepcopy(self.Î¸_0))
        self.Î·_t = deepcopy(self.Î·_0)
        self.q = deepcopy(q)                                  # sampler density
        
        # on s'assure de rentrer dans la boucle pour la premiÃ¨re itÃ©ration
        self.norm_grad_L : float = self.É› + 1
        
        # utilitaire
        self.counter : int = 0
        
        
        self.benchmark = benchmark
        # âš™ï¸ BENCHMARK
        if benchmark is True :
            self.benchmark_graph : list[list[float]] = [ list([]) for k in range( len(self.Î¸_t) + 1)]
            #                                [ list[counter], list[d_Î¼], list[d_Î£] ]
        
    def update_Î·(self) -> None:
        """modifie self.Î·_t selon la mÃ©thode choisie avec Î·_update_method
        """
        match self.Î·_update_method :
            case "fixed":
                self.update_Î·_fixed()
            case "fixed_decreasing_rate":
                self.update_Î·_fixed_decreasing_rate()
            case "hessian":
                self.update_Î·_hessian()
            case _ :
                # par dÃ©faut pa fixed
                err_str = f"/!\ {_} inconnu, utilisation du pas fixe..."
                print(err_str)
                debug(logstr(err_str))
                self.update_Î·_fixed()
    
    def update_Î·_fixed(self) -> None:
        # do nothing
        pass
    def update_Î·_fixed_decreasing_rate(self) -> None:
        #TODO
        pass
    def update_Î·_Hessian(self) -> None:
        #TODO
        pass
    def update_Î·_hessian(self) -> None:
        #TODO
        pass
    
    def get_current_theta(self) -> NDArray:
        return self.Î¸_t
    
    def execute(self) -> None:
        debug(logstr("executing gradient ascent :"))
        t = time.process_time()
        for counter in range(self.iter_limit) :
            debug(logstr(f"itÃ©ration nÂ°{counter}"))
            # si on atteint la prÃ©cision voulue en terme de norme : fin
            if self.norm_grad_L < self.É›:
                debug(logstr(
                    f"||âˆ‡L|| = {self.norm_grad_L} â¤ arrÃªt"
                ))
                break
            # sinon on continue
            else :
                debug(logstr(
                    f"||âˆ‡L|| = {self.norm_grad_L} â¤ nouvelle itÃ©ration"
                ))
                self.nouvelle_iteration()
        Î”t = time.process_time() - t
        debug(logstr(f"â±ï¸ â€”  {Î”t}"))
        
        
        # si on fait un benchmark
        if self.benchmark is True :
            
            n = len(self.Î¸_t)
            print(f"{self.Î¸_t}\n{n}")
            
            # 
            fig = make_subplots(
                                rows= n//2 + n%2 , cols=2,
                                subplot_titles= [ r"$\text{erreur relative : }" + "\\left| \\frac{" "Î¸_" + f"{k}" + "- Î¸^*_"f"{k}" +"}" + "{Î¸^*" + f"_{k}" + "}"  +"\\right|" "$" for k in range(n)]
                                )
            
            for k in range( n ):
                fig.add_trace(plgo.Scatter(x=self.benchmark_graph[0] , y=self.benchmark_graph[1+k]), row = 1 + k//2 , col = 1 + k%2)

            fig.show()
    
    
    def nouvelle_iteration(self):
        
        
        t = time.process_time()
        # Ã©tat des lieux dans le log
        debug(logstr(
            f"Ã©tat initial de l'itÃ©ration :\nÎ¸_t = {self.Î¸_t}\nÎ·_t = {self.Î·_t}"
            ))
        
        
        # new sample from qâ‚œ
        X_t = self.q.sample( self.nb_drawn_samples )
        
        if X_t is None :
            X_t = []        # comme Ã§a le hinter me laisse tranquille
            raise ValueError("âš ï¸ new sample from qâ‚œ is empty")
        
        debug(logstr(f"\nX = {X_t}\n\nlen(X) = {len(X_t)}"))
        
        
        #                           tirage de nouvelles observations selon le sampler q
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        
        # si le nombre d'obs tirÃ©es pour l'estimation du gradient est infÃ©rieur au nombre d'observations tirÃ©es dans le sample de qâ‚œ il s'agit d'un SGA
        if self.ğ›¾ < self.nb_drawn_samples :
            # Stochastic : choose random observations
            obs_tirÃ©es = nprd.choice(range(len(X_t)), self.ğ›¾, replace=False)
            
            # ğŸ’¡ NOTE : on pourrait s'intÃ©resser au papier 
            #           Adaptive Sampling for Incremental Optimization using Stochastic Gradient Descent (2015) â€” Papa
            #           sur la faÃ§on dont on tire des observations dans l'Ã©chantillon samplÃ©
            X_sampled_from_uniform = [  X_t[i] for i in obs_tirÃ©es  ]
            #                                             b inclu
            debug(logstr(f"\nX_sampled_from_uniform = {X_sampled_from_uniform}"))
        
        # si c'est = on a un GA classique
        elif self.ğ›¾ == self.nb_drawn_samples :
            debug(logstr("classic (non stochastic) gradient ascent"))
            X_sampled_from_uniform = X_t
        
        else :
            raise Exception(f"can't choose more values than generated : {self.ğ›¾} = ğ›¾ > nb_drawn_samples = {self.nb_drawn_samples}")
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        
        
        
        
        #                   on update la valeur du gradient de L selon la mÃ©thode de la SGD
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

        grad_L_list = self.grad_L_list(X_sampled_from_uniform, self.Î¸_t, known_len_X=self.ğ›¾)
        
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        #                             calcul de âˆ‡L â‹ 1/ğ›¾ Î£ âˆ‡L(X_i | Î¸)
        #                                             i âˆˆ {obs tirÃ©es}
        # 
        #                               rappel : card {obs tirÃ©es} = ğ›¾
        #  â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        
        
        grad_L_estimator : NDArray = np.add.reduce( grad_L_list )/self.ğ›¾
        
        debug(logstr(f"calcul de âˆ‡L â‹ 1/ğ›¾ Î£ âˆ‡L(X_i | Î¸)\n\ngrad_L_estimator = {grad_L_estimator}"))
        
        
        
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        #                                       update des (hyper) params
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        
        # paramÃ¨tre de distributoin q
        self.Î¸_t = self.Î¸_t + self.Î·_t * grad_L_estimator
        
        
        #?  â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”        DEBUG        â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        str_theta = f"Î¸_{self.counter} = {self.Î¸_t}"
        #! TOGGLE ON/OFF if needed or not
        print(str_theta)    #!          |
        #! â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        #?  â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        
        
                
        # sampling policy
        self.q.update_parameters(self.Î¸_t)
        
        # pas
        self.update_Î·()
        debug(logstr(f"{str_theta}\nÎ·_t+1 = {self.Î·_t}"))
        
        # â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
        
        self.counter += 1
        self.norm_grad_L = np.linalg.norm(self.Î·_t * grad_L_estimator)
        
        Î”t = time.process_time() - t
        debug(logstr(f"â±ï¸ â€”  {Î”t}"))
        
        
        if self.benchmark is True :
            target = self.f.parameters_list()
            self.benchmark_graph[0].append(self.counter)
            for k in range(len(self.Î¸_t)) :
                d_k = np.abs((self.Î¸_t[k] - target[k])/(target[k] + 1e-4))
                self.benchmark_graph[1+k].append(d_k)
            
        
        # on retourne aussi le dernier sample pour Ãªtre efficace en calcul pour l'algo qui va Ãªtre utilisÃ©
        return X_t
    
    
    
    def Ï‰(self, x : float,Î¸ : NDArray) -> float: 
        
        # indÃ©pendant de Î¸
        f_val = self.f.density(x)
        # dÃ©pendant de Î¸
        q_val = self.q.density_fcn(x, Î¸)
                
        res = f_val/q_val
        
        debug(logstr(f"Î¸ = {Î¸}\nf(x) = {f_val}\nq(x, theta) = {q_val}\nâ‡’ Ï‰(x,Î¸) = {res}"))
        return res
    
    
    
    
    def Ï‰_norm_list(self, X : list,Î¸ : NDArray, normalize : bool = True) -> NDArray: 
        
        t = time.process_time()
        
        Ï‰_list = np.array([ self.Ï‰(x, Î¸) for x in X ])
        if normalize is True :
            Ï‰_list = 1/(Ï‰_list.sum()) * Ï‰_list
        
        Î”t = time.process_time() - t
        debug(logstr(f"â±ï¸ â€”  {Î”t}"))
        
        return Ï‰_list
    
    
    
    
    def h(self,x : float,Î¸ : NDArray) -> NDArray:
        log_q = lambda u, v : np.log(self.q.density_fcn(u, v))
        res = gradient_selon(2, log_q , *[x, Î¸] )
        debug(logstr(f"h(x,Î¸) = {get_vector_str(res)}"))
        return res
    
    
    
    
    def grad_L_list(self, X : list[float], Î¸ : NDArray, known_len_X : int | None = None) -> NDArray:
        
        t = time.process_time()
        
        if known_len_X is None :
            n = len(X)
        else :
            n = known_len_X
        
        Ï‰_list = self.Ï‰_norm_list(X, Î¸, True)
        #                   on renormalise les poids aprÃ¨s les avoir calculÃ©s
        #                                           |
        #                                           â†“
        #gradL_list = np.array([self.h(X[i], Î¸) * Ï‰_list[i] for i in range(len(X))])
        gradL_list = np.array([self.grad_L(X[i], self.Î¸_t, self.norm_safety_coefficient, Ï‰_list[i]) for i in range(n)])
        
        Î”t = time.process_time() - t
        debug(logstr(f"calcul de âˆ‡L_list : {gradL_list[0:2]} ... {gradL_list[-1]}"))
        debug(logstr(f"â±ï¸ â€”  {Î”t}"))
        
        return gradL_list        

    
    def grad_L(self, x_i : float, Î¸ : NDArray, norm_safety_coefficient : float, Ï‰_i : float) -> NDArray:
        
        t = time.process_time()
                
        #                   importance sampling selon q(Î¸)
        #                                  |
        #                                  â†“
        #? changement
        #res = self.h(x_i, Î¸) * self.Ï‰(x_i, Î¸)
        res = self.h(x_i, Î¸) * Ï‰_i
        
        debug(logstr(f"âˆ‡L_i(Î¸) = \n{get_vector_str(res)}"))
        
        norm_res = np.linalg.norm(res)
        norm_theta = np.linalg.norm(np.array(Î¸))
        
        # avec les Ï‰, si on a un Ï‰ ~ 10 000 lorsque q << f 
        # on va avoir la norme de la direction qui explose
        # on essaye d'Ã©viter cela
        
        
        # si le gradient est aberrant en i selon le coefficient de sÃ©curitÃ©
        # on ne le compte pas
        if norm_res > norm_safety_coefficient * norm_theta :
            debug(logstr(f"{norm_res} = || res || > {norm_safety_coefficient} x || Î¸ || = {norm_safety_coefficient*norm_theta}\n\nreturning zeros..."))
            return np.zeros(Î¸.shape)
        
        Î”t = time.process_time() - t
        debug(logstr(f"â±ï¸ â€”  {Î”t}"))
        
        return res
