import numpy as np
from copy import deepcopy

# typing
from typing import Callable, Any, Optional, Tuple, Literal
from numpy.typing import ArrayLike, NDArray

# random
from random import randint
import numpy.random as nprd

# My Modules
from math_tools.gradient import gradient_selon
from math_tools.distribution_family import DistributionFamily

# Debug
from utils.log import logstr
from logging import info, debug, warn, error
from utils.print_array_as_vector import get_vector_str

# Plots
import plotly.express as plx
from plotly.subplots import make_subplots
import plotly.graph_objects as plgo


def initialisation(q, É›, Î¸_0, N, ğ›¾, Î·_0, benchmark) -> Tuple[float, NDArray, float, list[float],DistributionFamily, list[list[float]] | None, list[bool]]:
    """initialisationdes paramÃ¨tres pour la SGA de la fonction L
    
    
    Inputs : 
    
        q                               â€” original sampling policy : q(ğ‘¥, Î¸)
        
        É›                               â€” threshold pour la norme du gradient
        
        Î¸_0                             â€” initialisation des paramÃ¨tres
        
        nb_drawn_samples (N)            â€” Nombre de samples tirÃ©s par la distribution q Ã  chaque itÃ©ration
        
        nb_stochastic_choice (ğ›¾)        â€” nombre d'observations Ã  tirer alÃ©atoirement
        
        step (Î·_0)                      â€” initialisation du pas
        
        benchmark                       - if True, produces error graphs




    Return :
    
        Î·_t, Î¸_t, norm_grad_L, X, q_0, counter, benchmark_graph, state
        
        Î·_t             : float
        Î¸_t             : NDArray
        norm_grad_L     : float
        X               : list[float]
        q_0             : DistributionFamily
        benchmark_graph : list[list[float]] | None
        state           : list[bool]
    
    """
    
    """TYPES DEFINITION"""
    Î·_t             : float
    Î¸_t             : NDArray
    norm_grad_L     : float
    X               : list[float]
    q_0             : DistributionFamily
    counter         : int
    benchmark_graph : list[list[float]] | None
    state           : list[bool]
    
    # initialisation
    Î·_t = Î·_0
    if Î¸_0 is None :
        Î¸_0 = q.parameters_list()
        Î¸_t = q.parameters_list()
    else :
        Î¸_t = Î¸_0
        q.update_parameters(Î¸_0)
    # on s'assure de commencer la premiÃ¨re itÃ©ration
    norm_grad_L = (É› + 1)
    
    X = []
    
    debug(logstr(
        f"\nÎ·_t = {Î·_t}\nÎ¸_t = {Î¸_t}\nğ›¾ = {ğ›¾}\nN = {N}\n"
                ))
    
    #! importance sampling selon q(Î¸_0)
    q_0 = q.copy()
        
    
    if benchmark is True :
        benchmark_graph = [ list([]) for k in range( len(Î¸_t) + 1)]
    else :
        benchmark_graph = None

    state = [False for k in range(3)]
    
    return Î·_t, Î¸_t, norm_grad_L, X, q_0, benchmark_graph, state



def update_Î·(Î·_t):
    Î·_t_plus_1 = Î·_t
    return Î·_t_plus_1


def cond_n_de_suite__update_state(cond, state : list[bool]) -> list[bool]:
    # true and false in state
    if all(state):
        new_state = state
    else:
        if cond is True:
            first_false = state.index(False)
            new_state = deepcopy(state)
            new_state[first_false] = True
        else:
            new_state = [False for k in range(len(state))]
    # all true
    return new_state



def compute_grad_L_estimator(f_target, q, Î¸_t, nb_stochastic_choice,max_L_gradient_norm, X_sampled_from_uniform) -> NDArray:
    def Ï‰(x,Î¸) -> float:
        f_val = f_target.density(x)
        q_val = q.density_fcn(x, Î¸)
        res = f_val/q_val
        debug(logstr(f"Ï‰(x,Î¸) = {res}"))
        return res
    # âŸ¶ scalaire

    def h(x,Î¸) -> NDArray:
        res = gradient_selon(2, lambda u, v : np.log(q.density_fcn(u, v)), *[x, Î¸] )
        debug(logstr(f"h(x,Î¸) = {get_vector_str(res)}"))
        return res
    # âŸ¶ vecteur
    
    def grad_L(x_i, Î¸) -> NDArray:
        res = h(x_i, Î¸) * Ï‰(x_i, Î¸) #@ #res = h(x_i, Î¸) * Ï‰(x_i, Î¸_0 )            
        norm_res = np.linalg.norm(res)
        norm_theta = np.linalg.norm(np.array(Î¸))
        # avec les Ï‰, si on a un Ï‰ ~ 10 000 lorsque q << f 
        # on va avoir la norme de la direction qui explose
        # on essaye d'Ã©viter cela
        if norm_res > max_L_gradient_norm * norm_theta :
            debug(logstr(f"{norm_res} = || res || > {max_L_gradient_norm} x || Î¸ || = {max_L_gradient_norm*norm_theta}\n\nreturning zeros..."))
            # return np.zeros(Î¸.shape)
            return max_L_gradient_norm * (res/norm_res)
        return res
    # âŸ¶ vecteur

    grad_L_list : list[NDArray] = [ grad_L(x_i = X_sampled_from_uniform[i], Î¸ = Î¸_t) for i in range(nb_stochastic_choice) ]
    
    grad_L_estimator : NDArray = np.add.reduce( grad_L_list )/nb_stochastic_choice
    
    return grad_L_estimator



def sga_kullback_leibler_likelihood(
     f_target : DistributionFamily ,
     q_init : DistributionFamily , 
     nb_drawn_samples : int, 
     nb_stochastic_choice : int, 
     step : float, 
     Î¸_0 : Optional[ArrayLike] = None, 
     É› : float = 1e-6, 
     iter_limit = 100, 
     benchmark : bool = False, 
     max_L_gradient_norm : int = 10
) -> NDArray:
    """effectue une stochastic gradient ascent pour le problÃ¨me d'optimisation de Î¸ suivant le critÃ¨re de la vraissemblance de Kullback-Leibler
        
    f                               â€” target density
                                        â¤ va Ãªtre utilisÃ©e pour la comparaison avec q dans la maximisation de la vraissemblance de Kullback-Leibler
                                        
                                        L(Î¸) = - KL( f || q )
    
    q                               â€” original sampling policy : q(ğ‘¥, Î¸)
    
                                                        parametric family of sampling policies / distributions
                                                        given as a (lambda) function of ğ‘¥, Î¸ âˆˆ ğ˜Ÿ Ã— Î˜

                                                        q = lambda x,Î¸ : np.exp( - (x-Î¸[0])**2 / (2*Î¸[1]) )/(np.sqrt(2*np.pi*Î¸[1]))
                                                        gives a normal law density

                                    â¤ va Ãªtre modifiÃ©e Ã  chaque itÃ©ration
    
    
    nb_drawn_samples (N)            â€” Nombre de samples tirÃ©s par la distribution q Ã  chaque itÃ©ration
    
    nb_stochastic_choice (ğ›¾)        â€” nombre d'observations Ã  tirer alÃ©atoirement
    
    step (Î·_0)                      â€” initialisation du pas
    
    Î¸_0                             â€” initialisation des paramÃ¨tres
    
    É›                               â€” threshold pour la norme du gradient
    
    iter_limit                      - nombre d'itÃ©rations max du gradient descent avant l'arrÃªt

    benchmark                       - if True, produces error graphs
    
    max_L_gradient_norm             - safety coefficient : if â€– ğ›L â€– > ğœ¶ â€– Î¸_t â€–
                                        â†ª we use ğœ¶ Ã— (ğ›L / â€– ğ›L â€–)
    """
    
    Î·_t, Î¸_t, norm_grad_L, X, q, benchmark_graph, state = initialisation(q_init, É›, Î¸_0, nb_drawn_samples, nb_stochastic_choice, step, benchmark)
    # useful for computing error
    if benchmark_graph is not None :
        target : NDArray = f_target.parameters_list()
    
    # new_samples = []
    
    for counter in range(iter_limit):
        if all(cond_n_de_suite__update_state(norm_grad_L <= É›, state)):
            debug(logstr(f"norm_grad_L = {norm_grad_L}"))
            break
        
        new_sample : list | None = q.sample(nb_drawn_samples)
        # new_samples.append(new_sample)
        if new_sample is None :
            raise ValueError(f"could not sample from q \n(params = {q.parameters})\nnew_sample = None")
        
        # todo
        # comprendre pourquoi si je mets juste X = new_sample
        # on finit par avoir des variances nÃ©gatives ?
        X = new_sample #+ X
        # X = new_samples.pop(0)
        
        if nb_stochastic_choice == nb_drawn_samples :
            X_sampled_from_uniform = X
        else :
            obs_tirÃ©es = nprd.choice(range(len(X)), nb_stochastic_choice, replace=False)
            X_sampled_from_uniform = [  X[i] for i in obs_tirÃ©es  ]
        
        
        # ğ›L
        grad_L_estimator = compute_grad_L_estimator(f_target, q, Î¸_t, nb_stochastic_choice,max_L_gradient_norm, X_sampled_from_uniform)
        # â€–ğ›Lâ€–
        norm_grad_L = np.linalg.norm(grad_L_estimator)
        
        # gradient ascent
        Î¸_t = Î¸_t + Î·_t * grad_L_estimator
        
        str_theta = f"Î¸_{counter} = {Î¸_t}"
        print(str_theta)
        debug(logstr(str_theta))
        
        # aprameters update
        q.update_parameters(Î¸_t)
        
        Î·_t = update_Î·(Î·_t)
        debug(logstr(f"Î·_t+1 = {Î·_t}"))
        
        # if we desire to benchmark : we build the error graph
        if benchmark_graph is not None :
            
            #           X AXIS
            benchmark_graph[0].append(counter)
            
            #           Y AXIS
            for k in range(len(Î¸_t)) :
                # we add the relative error between Î¸_t and Î¸_target
                d_k = np.abs((Î¸_t[k] - target[k])/(target[k] + 1e-4))
                #####################################################
                benchmark_graph[1+k].append(d_k)
        
    # Ã  la fin on plot le graphe des erreurs
    if benchmark_graph is not None :
        fig = make_subplots(
                            rows= len(Î¸_t)//2 + len(Î¸_t)%2 , cols=2,
                            subplot_titles= [ r"$\text{erreur relative : }" + "\\left| \\frac{" "Î¸_" + f"{k}" + "- Î¸^*_"f"{k}" +"}" + "{Î¸^*" + f"_{k}" + "}"  +"\\right|" "$" for k in range(len(Î¸_t))]
                    )
        for k in range(len(Î¸_t)):
            print(f"({1 + k//2}, {1 + k%2})")
            fig.add_trace(plgo.Scatter(x=benchmark_graph[0] , y=benchmark_graph[1+k]), row = 1 + k//2 , col = 1 + k%2)
        fig.show()
        
    return Î¸_t




