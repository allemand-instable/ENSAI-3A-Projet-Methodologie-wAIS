import numpy as np
from copy import deepcopy

# typing
from typing import Callable, Any, Dict, List, Optional, Tuple, Literal
from numpy.typing import ArrayLike, NDArray

# random
from random import randint
import numpy.random as nprd

# My Modules
from gradient.gradient import gradient_selon
from distribution_family.distribution_family import DistributionFamily

# Debug
from utils.log import logstr
from logging import info, debug, warn, error
from utils.print_array_as_vector import get_vector_str

# Plots
import plotly.express as plx
from plotly.subplots import make_subplots
import plotly.graph_objects as plgo

#? BenchmarkGraph = Optional[List[ List[int]   | List[float] ]]
#                                  iterations  |   erreur relative √† composante k ‚àà ‚ü¶1,len(Œ∏‚Çú)‚üß
#    index :                       0           |   1, ... , n = len(Œ∏‚Çú)
#    passe mieux pour le type hinting m√™me si le vrai est plut√¥t en haut
BenchmarkGraph = Optional[List[ List[float] ]]

ParamsInitiaux = Tuple[ float,                  # Œ∑_t
                        NDArray,                # Œ∏_t
                        float,                  # norm_grad_L
                        List[float],            # X
                        DistributionFamily,     # q_0
                        BenchmarkGraph,         # benchmark_graph
                        List[bool]              # state
                      ]

def initialisation(q : DistributionFamily, …õ : float, Œ∏_0 : Optional[NDArray], N : int, ùõæ : float, Œ∑_0 : float, benchmark : bool) -> ParamsInitiaux:
    """initialisationdes param√®tres pour la SGA de la fonction L
    
    
    Inputs : 
    
        q                               ‚Äî original sampling policy : q(ùë•, Œ∏)
        
        …õ                               ‚Äî threshold pour la norme du gradient
        
        Œ∏_0                             ‚Äî initialisation des param√®tres
        
        nb_drawn_samples (N)            ‚Äî Nombre de samples tir√©s par la distribution q √† chaque it√©ration
        
        nb_stochastic_choice (ùõæ)        ‚Äî nombre d'observations √† tirer al√©atoirement
        
        step (Œ∑_0)                      ‚Äî initialisation du pas
        
        benchmark                       - if True, produces error graphs




    Return :
    
        Œ∑_t, Œ∏_t, norm_grad_L, X, q_0, counter, benchmark_graph, state
        
        Œ∑_t             : float
        Œ∏_t             : NDArray
        norm_grad_L     : float
        X               : list[float]
        q_0             : DistributionFamily
        benchmark_graph : list[list[float]] | None
        state           : list[bool]
    
    """
    
    """TYPES DEFINITION"""
    Œ∑_t             : float
    Œ∏_t             : NDArray
    norm_grad_L     : float
    X               : list[float]
    q_0             : DistributionFamily
    counter         : int
    benchmark_graph : list[list[float]] | None
    state           : list[bool]
    
    # initialisation
    Œ∑_t = Œ∑_0
    if Œ∏_0 is None :
        Œ∏_0 = q.parameters_list()
        Œ∏_t = q.parameters_list()
    else :
        Œ∏_t = Œ∏_0
        q.update_parameters(Œ∏_0)
    # on s'assure de commencer la premi√®re it√©ration
    norm_grad_L = (…õ + 1)
    
    X = []
    
    debug(logstr(
        f"\nŒ∑_t = {Œ∑_t}\nŒ∏_t = {Œ∏_t}\nùõæ = {ùõæ}\nN = {N}\n"
                ))
    
    #! importance sampling selon q(Œ∏_0)
    q_0 = q.copy()
        
    
    if benchmark is True :
        benchmark_graph = [ list([]) for k in range( len(Œ∏_t) + 1)]
    else :
        benchmark_graph = None

    state = [False for k in range(3)]
    
    return Œ∑_t, Œ∏_t, norm_grad_L, X, q_0, benchmark_graph, state



def update_Œ∑(Œ∑_t : float) -> float:
    """fonction d'update du pas : ici constante, mais devrait √™tre mise en pas variable pour une meilleure convergence"""
    Œ∑_t_plus_1 = Œ∑_t
    return Œ∑_t_plus_1


def cond_n_de_suite__update_state(cond, state : list[bool]) -> list[bool]:
    """lors du Gradient Ascent, on veut arr√™ter les it√©rations si on remarque que la norme du gradient est en dessous d'un seuil | pour s'assurer de ne pas √™tre dans un minimum local non global, on regarde si cette condition est v√©rifi√©e plusieurs fois d'affil√©e"""
    # true and false in state
    if all(state):
        new_state = state
    else:
        if cond is True:
            first_false = state.index(False)
            new_state = deepcopy(state)
            new_state[first_false] = True
        else:
            new_state = [False for k in range(len(state))]
    # all true
    return new_state


""""""
def compute_grad_L_estimator(f_target : DistributionFamily, 
                             q : DistributionFamily, 
                             Œ∏_t : NDArray, 
                             nb_stochastic_choice : int,
                             max_L_gradient_norm : int | float, 
                             X_sampled_from_uniform : List[float]
                             ) -> NDArray:
    """calcul de l'estimateur de ùõÅL(Œ∏) obtenu par la loi des grands nombres et la m√©thode d'Importance Sampling
    
    ùõÅ_Œ∏ ‚à´ f(u)√ólog[q_Œ∏(u)]du = ‚à´    f(u)       √ó ùõÅ_Œ∏[log q_Œ∏(u)] du 
                             = ‚à´ [f(u)/q_Œ∏(u)] √ó ùõÅ_Œ∏[log q_Œ∏(u)] √ó q_Œ∏(u) du
                             = ùîº_Œ∏[ (f(u)/q_Œ∏(u)) √ó ùõÅ_Œ∏(log q_Œ∏(u)) ]   
    """
    def œâ(x,Œ∏) -> float:
        f_val = f_target.density(x)
        q_val = q.density_fcn(x, Œ∏)
        res = f_val/q_val
        # debug(logstr(f"œâ(x,Œ∏) = {res}"))
        return res
    # ‚ü∂ scalaire

    def h(x,Œ∏) -> NDArray:
        # x ‚üº log q‚Çú(x)
        def log_q(u, theta) -> float :
            return np.log(q.density_fcn(u, theta)) 
        # [ùõÅ_Œ∏]log q‚Çú(x)
        res = gradient_selon(2, log_q, *[x, Œ∏] )
        # debug(logstr(f"h(x,Œ∏) = {get_vector_str(res)}"))
        return res
    # ‚ü∂ vecteur
    
    def grad_L(x_i, Œ∏) -> NDArray:
        res = h(x_i, Œ∏) * œâ(x_i, Œ∏) #@ #res = h(x_i, Œ∏) * œâ(x_i, Œ∏_0 )            
        norm_res = np.linalg.norm(res)
        norm_theta = np.linalg.norm(np.array(Œ∏))
        # avec les œâ, si on a un œâ ~ 10 000 lorsque q << f 
        # on va avoir la norme de la direction qui explose
        # on essaye d'√©viter cela
        if norm_res > max_L_gradient_norm * norm_theta :
            debug(logstr(f"{norm_res} = || res || > {max_L_gradient_norm} x || Œ∏ || = {max_L_gradient_norm*norm_theta}\n\nreturning zeros..."))
            # norm_max * ùõÅL/‚ÄñùõÅL‚Äñ
            return max_L_gradient_norm * (res/norm_res)
        return res
    # ‚ü∂ vecteur

    grad_L_list : list[NDArray] = [ grad_L(x_i = X_sampled_from_uniform[i], Œ∏ = Œ∏_t) for i in range(nb_stochastic_choice) ]
    
    grad_L_estimator : NDArray = np.add.reduce( grad_L_list )/nb_stochastic_choice
    
    return grad_L_estimator


def compute_grad_L_estimator_adaptive(  f_target : DistributionFamily, 
                                        q_t : DistributionFamily, 
                                        Œ∏_t : NDArray, 
                                        nb_stochastic_choice : int,
                                        max_L_gradient_norm : int | float, 
                                        X_sampled_from_uniform : List[float]
                             ) -> NDArray:
    """calcul de l'estimateur de ùõÅL(Œ∏) obtenu par la loi des grands nombres et la m√©thode d'Importance Sampling avec un q adaptatif
    
    œâ_Œ∏ = f / q_Œ∏
    on a donc ÃÇùõÅL = 1/n‚ãÖ‚àë [ùõÅ_Œ∏]( œâ_Œ∏ √ó log(q_Œ∏) )[X_i]
    """
    def œâ(x,Œ∏) -> float:
        f_val = f_target.density(x)
        q_val = q_t.density_fcn(x, Œ∏)
        res = f_val/q_val
        # debug(logstr(f"œâ(x,Œ∏) = {res}"))
        return res
    # ‚ü∂ scalaire

    def grad_L(x_i, Œ∏) -> NDArray:
        
        def log_q(u, theta) -> float :
            return np.log(q_t.density_fcn(u, theta)) 
        
        fcn = lambda x, theta : œâ(x, theta) * log_q(x, theta)
        res = gradient_selon(2, fcn, *[x_i, Œ∏])
        
        norm_res = np.linalg.norm(res)
        norm_theta = np.linalg.norm(np.array(Œ∏))
        # avec les œâ, si on a un œâ ~ 10 000 lorsque q << f 
        # on va avoir la norme de la direction qui explose
        # on essaye d'√©viter cela
        if norm_res > max_L_gradient_norm * norm_theta :
            debug(logstr(f"{norm_res} = || res || > {max_L_gradient_norm} x || Œ∏ || = {max_L_gradient_norm*norm_theta}\n\nreturning zeros..."))
            # norm_max * ùõÅL/‚ÄñùõÅL‚Äñ
            return max_L_gradient_norm * (res/norm_res)
        return res
    # ‚ü∂ vecteur

    grad_L_list : list[NDArray] = [ grad_L(x_i = X_sampled_from_uniform[i], Œ∏ = Œ∏_t) for i in range(nb_stochastic_choice) ]
    
    grad_L_estimator : NDArray = np.add.reduce( grad_L_list )/nb_stochastic_choice
    
    return grad_L_estimator



def compute_grad_L_estimator_importance_sampling(f_target : DistributionFamily, 
                             q_t : DistributionFamily, 
                             q_importance_sampling : DistributionFamily,
                             Œ∏_t : NDArray, 
                             nb_stochastic_choice : int,
                             max_L_gradient_norm : int | float, 
                             X_sampled_from_uniform : List[float]
                             ) -> NDArray:
    """calcul de l'estimateur de ùõÅL(Œ∏) obtenu par la loi des grands nombres et la m√©thode d'Importance Sampling
    
    œâ = f / q_importance_sampling
    
    on a donc ùõÅÃÇL = 1/n‚ãÖ‚àë [ùõÅ_Œ∏]( œâ √ó log(q_Œ∏) )[X_i]
                 = 1/n‚ãÖ‚àë  œâ[X_i] √ó [ùõÅ_Œ∏]log(q_Œ∏)[X_i]"""
    def œâ(x,Œ∏) -> float:
        f_val = f_target.density(x)
        q_val = q_importance_sampling.density_fcn(x, Œ∏)
        res = f_val/q_val
        # debug(logstr(f"œâ(x,Œ∏) = {res}"))
        return res
    # ‚ü∂ scalaire

    def h(x,Œ∏) -> NDArray:
        # x ‚üº log q‚Çú(x)
        def log_q(u, theta) -> float :
            return np.log(q_t.density_fcn(u, theta)) 
        # [ùõÅ_Œ∏]log q‚Çú(x)
        res = gradient_selon(2, log_q, *[x, Œ∏] )
        # debug(logstr(f"h(x,Œ∏) = {get_vector_str(res)}"))
        return res
    # ‚ü∂ vecteur
    
    def grad_L(x_i, Œ∏) -> NDArray:
        res = h(x_i, Œ∏) * œâ(x_i, Œ∏) #@ #res = h(x_i, Œ∏) * œâ(x_i, Œ∏_0 )            
        norm_res = np.linalg.norm(res)
        norm_theta = np.linalg.norm(np.array(Œ∏))
        # avec les œâ, si on a un œâ ~ 10 000 lorsque q << f 
        # on va avoir la norme de la direction qui explose
        # on essaye d'√©viter cela
        if norm_res > max_L_gradient_norm * norm_theta :
            debug(logstr(f"{norm_res} = || res || > {max_L_gradient_norm} x || Œ∏ || = {max_L_gradient_norm*norm_theta}\n\nreturning zeros..."))
            # norm_max * ùõÅL/‚ÄñùõÅL‚Äñ
            return max_L_gradient_norm * (res/norm_res)
        return res
    # ‚ü∂ vecteur

    grad_L_list : list[NDArray] = [ grad_L(x_i = X_sampled_from_uniform[i], Œ∏ = Œ∏_t) for i in range(nb_stochastic_choice) ]
    
    grad_L_estimator : NDArray = np.add.reduce( grad_L_list )/nb_stochastic_choice
    
    return grad_L_estimator





def show_error_graph(last_Œ∏_t : NDArray, Œ∏_target : NDArray, Œ∏_init : NDArray, benchmark_graph : BenchmarkGraph,
                     nb_drawn_samples, nb_stochastic_choice, step, max_L_gradient_norm  # subtitle parameters
                    ) -> None:
    """√† partir du r√©sultat de la SGA et des param√®tres initiaux, produit le graphe des erreurs **relatives** du param√®tre obtenu √† partir du param√®tre qui √©tait vis√©, et ce en produisant un graphe composante par composante du param√®tre Œ∏ estim√©"""
    if benchmark_graph is None :
        raise TypeError("the benchmark_graph should not be None")
    
    n = len(last_Œ∏_t)
    
    fig = make_subplots(
                        rows= n//2 + n%2 , cols=2,
                        subplot_titles= [ r"$\text{erreur relative : }" + "\\left| \\frac{" "Œ∏_" + f"{k}" + "- Œ∏^*_"f"{k}" +"}" + "{Œ∏^*" + f"_{k}" + "}"  +"\\right|" "$" for k in range(n)]
                )
    
    axis_range_dict = {}
    
    for k in range(n):
        # print(f"({1 + k//2}, {1 + k%2})")
        fig.add_trace(plgo.Scatter(x=benchmark_graph[0] , y=benchmark_graph[1+k]), row = 1 + k//2 , col = 1 + k%2)
        y_max = max(benchmark_graph[1+k])
        axis_range_dict[f"yaxis{k+1}"] = dict(range=[0, 1.1 * y_max])
    
    fig.update_xaxes(title_text='iteration')
    fig.update_yaxes(title_text='Relative error to target parameter')
    
    
    
    fig.update_layout(title=f"Œ∏_target = {[round(composante, 2) for composante in Œ∏_target]}      Œ∏_init = {[round(composante, 2) for composante in Œ∏_init]} <br><br><sup>N = {nb_drawn_samples}  |  ùõæ = {nb_stochastic_choice}  | Œ∑‚ÇÄ = {step}  | safety_coeff = {max_L_gradient_norm}</sup>",
    **axis_range_dict)
    fig.show()


def combine_error_graph(list_last_Œ∏_t : Dict[str, NDArray], Œ∏_target : NDArray, Œ∏_init : NDArray, list_benchmark_graph : Dict[str, BenchmarkGraph],
                     color_dict : Dict[str, str], nb_drawn_samples, nb_stochastic_choice, step, max_L_gradient_norm  # subtitle parameters
                    ) -> None:
    """√† partir du r√©sultat de la SGA et des param√®tres initiaux, produit le graphe des erreurs **relatives** du param√®tre obtenu √† partir du param√®tre qui √©tait vis√©, et ce en produisant un graphe composante par composante du param√®tre Œ∏ estim√©"""
    if not(len(list_last_Œ∏_t) == len(list_benchmark_graph)) :
        raise ValueError("lists are not of the same lenghth")        
    
    n = [len(list_last_Œ∏_t[key]) for key in list_last_Œ∏_t][0]
    
    fig = make_subplots(
                        rows= n//2 + n%2 , cols=2,
                        subplot_titles= [ r"$\text{erreur relative : }" + "\\left| \\frac{" "Œ∏_" + f"{k}" + "- Œ∏^*_"f"{k}" +"}" + "{Œ∏^*" + f"_{k}" + "}"  +"\\right|" "$" for k in range(n)]
                )
    
    axis_range_dict = {}
    
    y_max_list = []
    
    for k in range(n):
        y_max_list.append( max([max(benchmark_graph[1+k]) for key, benchmark_graph in list_benchmark_graph.items() if benchmark_graph is not None]) )
    
    for key, benchmark_graph in list_benchmark_graph.items() :
        if benchmark_graph is None :
            raise TypeError("the benchmark_graph should not be None")
        for k in range(n):
            # print(f"({1 + k//2}, {1 + k%2})")
            fig.add_trace(plgo.Scatter(x=benchmark_graph[0] , y=benchmark_graph[1+k], name=f"Œ∏_{k} : {key}", marker_color=color_dict[key]), row = 1 + k//2 , col = 1 + k%2)
            y_max = y_max_list[k]
            print(y_max)
            axis_range_dict[f"yaxis{k+1}"] = dict(range=[0, 1.1 * y_max])
        
    fig.update_xaxes(title_text='iteration')
    fig.update_yaxes(title_text='Relative error to target parameter')
    
    
    
    fig.update_layout(title=f"Œ∏_target = {[round(composante, 2) for composante in Œ∏_target]}      Œ∏_init = {[round(composante, 2) for composante in Œ∏_init]} <br><br><sup>N = {nb_drawn_samples}  |  ùõæ = {nb_stochastic_choice}  | Œ∑‚ÇÄ = {step}  | safety_coeff = {max_L_gradient_norm}</sup>",
    **axis_range_dict)
    fig.show()



def sga_kullback_leibler_likelihood(
                                        f_target : DistributionFamily ,
                                        q_init : DistributionFamily , 
                                        nb_drawn_samples : int, 
                                        nb_stochastic_choice : int, 
                                        step : float, 
                                        Œ∏_0 : Optional[NDArray] = None, 
                                        …õ : float = 1e-6, 
                                        iter_limit = 100, 
                                        benchmark : bool = False, 
                                        max_L_gradient_norm : int | float = np.Infinity,
                                        adaptive : bool = False,
                                        weight_in_gradient : bool = False,
                                        show_benchmark_graph : bool = False
                                    ) -> Tuple[NDArray, Optional[BenchmarkGraph]]:
    """effectue une stochastic gradient ascent pour le probl√®me d'optimisation de Œ∏ suivant le crit√®re de la vraissemblance de Kullback-Leibler
        
    f_target                        ‚Äî target density
                                        ‚û§ va √™tre utilis√©e pour la comparaison avec q dans la maximisation de la vraissemblance de Kullback-Leibler
                                        
                                        L(Œ∏) = - KL( f || q )
    
    q_init                          ‚Äî original sampling policy : q(ùë•, Œ∏)
    
                                                        parametric family of sampling policies / distributions
                                                        given as a (lambda) function of ùë•, Œ∏ ‚àà ùòü √ó Œò

                                                        q = lambda x,Œ∏ : np.exp( - (x-Œ∏[0])**2 / (2*Œ∏[1]) )/(np.sqrt(2*np.pi*Œ∏[1]))
                                                        gives a normal law density

                                    ‚û§ va √™tre modifi√©e √† chaque it√©ration
    
    
    nb_drawn_samples (N)            ‚Äî Nombre de samples tir√©s par la distribution q √† chaque it√©ration
    
    nb_stochastic_choice (ùõæ)        ‚Äî nombre d'observations √† tirer al√©atoirement
    
    step (Œ∑_0)                      ‚Äî initialisation du pas
    
    Œ∏_0                             ‚Äî initialisation des param√®tres
    
    …õ                               ‚Äî threshold pour la norme du gradient
    
    iter_limit                      ‚Äî nombre d'it√©rations max du gradient descent avant l'arr√™t

    benchmark                       ‚Äî if True, produces error graphs
    
    max_L_gradient_norm             ‚Äî safety coefficient : if ‚Äñ ùõÅL ‚Äñ > ùú∂ ‚Äñ Œ∏_t ‚Äñ
                                        ‚Ü™ we use ùú∂ √ó (ùõÅL / ‚Äñ ùõÅL ‚Äñ)
                                        ‚Ü™ Default : unbound         [ np.Infinity ]
                                        
    adaptive                        ‚Äî sample X = (ùë•·µ¢)‚ÇÅ,‚Çô
                                            ‚Ü™ √† partir de q_init    [ False ]
                                            
                                            ‚Ü™ √† partir de q‚Çú        [ True  ]
                                            
    """
    
    Œ∑_t, Œ∏_t, norm_grad_L, X, q, benchmark_graph, state = initialisation(q_init, …õ, Œ∏_0, nb_drawn_samples, nb_stochastic_choice, step, benchmark)
    # useful for computing error
    if benchmark_graph is not None :
        target : NDArray = f_target.parameters_list()
        theta_init = deepcopy(Œ∏_t)
    else :
        target = np.array([])
        theta_init = np.array([])
    
    # new_samples = []
    if not adaptive :
        X = q_init.sample(500)
        if X is None :
            X = []
            raise ValueError("generated sample is None !")
    else :
        X = []
    
    for counter in range(iter_limit):
        if all(cond_n_de_suite__update_state(norm_grad_L <= …õ, state)):
            debug(logstr(f"norm_grad_L = {norm_grad_L}"))
            break
        
        if adaptive :
            new_sample : list | None = q.sample(nb_drawn_samples)
            # new_samples.append(new_sample)
            if new_sample is None :
                raise ValueError(f"could not sample from q \n(params = {q.parameters})\nnew_sample = None")
            # todo
            # comprendre pourquoi si je mets juste X = new_sample
            # on finit par avoir des variances n√©gatives ?
            else :
                X = new_sample + X
            # X = new_samples.pop(0)
        
        if nb_stochastic_choice == nb_drawn_samples :
            X_sampled_from_uniform = X
        else :
            obs_tir√©es = nprd.choice(range(len(X)), nb_stochastic_choice, replace=False)
            X_sampled_from_uniform = [  X[i] for i in obs_tir√©es  ]
        
        
        # ùõÅL
        if adaptive :
            if weight_in_gradient :
                grad_L_estimator = compute_grad_L_estimator_adaptive(f_target, q, 
                                                            Œ∏_t, 
                                                            nb_stochastic_choice,
                                                            max_L_gradient_norm, 
                                                            X_sampled_from_uniform)
            else :
                grad_L_estimator = compute_grad_L_estimator_importance_sampling(f_target, q, q,
                                                            Œ∏_t, 
                                                            nb_stochastic_choice,
                                                            max_L_gradient_norm, 
                                                            X_sampled_from_uniform)
        else :
            grad_L_estimator = compute_grad_L_estimator_importance_sampling(f_target, q, q_init,
                                                        Œ∏_t, 
                                                        nb_stochastic_choice,
                                                        max_L_gradient_norm, 
                                                        X_sampled_from_uniform)
        # ‚ÄñùõÅL‚Äñ
        norm_grad_L = np.linalg.norm(grad_L_estimator)
        
        # gradient ascent
        Œ∏_t = Œ∏_t + Œ∑_t * grad_L_estimator
        
        str_theta = f"Œ∏_{counter} = {Œ∏_t}"
        print(str_theta)
        debug(logstr(str_theta))
        
        # aprameters update
        q.update_parameters(Œ∏_t)
        # print(q.parameters)
        
        Œ∑_t = update_Œ∑(Œ∑_t)
        debug(logstr(f"Œ∑_t+1 = {Œ∑_t}"))
        
        # if we desire to benchmark : we build the error graph
        if benchmark_graph is not None :
            
            #           X AXIS
            benchmark_graph[0].append(counter)
            
            #           Y AXIS
            for k in range(len(Œ∏_t)) :
                # we add the relative error between Œ∏_t and Œ∏_target
                d_k = np.abs((Œ∏_t[k] - target[k])/(target[k] + 1e-4))
                #####################################################
                benchmark_graph[1+k].append(d_k)
        
    # √† la fin on plot le graphe des erreurs
    if (benchmark_graph is not None) and (show_benchmark_graph is True) :
        show_error_graph(last_Œ∏_t = Œ∏_t, 
                         Œ∏_target = target, 
                         Œ∏_init = theta_init,
                         benchmark_graph = benchmark_graph,
                         # subtitle
                         nb_drawn_samples = nb_drawn_samples, 
                         nb_stochastic_choice = nb_stochastic_choice, 
                         step = step, 
                         max_L_gradient_norm= max_L_gradient_norm
                         )        
    if benchmark :
        return Œ∏_t, benchmark_graph
    else :
        return Œ∏_t, None


def compare_sga_methods(
                        f_target : DistributionFamily ,
                        q_init : DistributionFamily , 
                        nb_drawn_samples : int, 
                        nb_stochastic_choice : int, 
                        step : float, 
                        …õ : float = 1e-6, 
                        iter_limit = 100, 
                        max_L_gradient_norm : int | float = np.Infinity) -> None:
    # adaptive : false
    # weight in grad : false
    last_param_1, graph1 = sga_kullback_leibler_likelihood(f_target, q_init, nb_drawn_samples, nb_stochastic_choice, step, None,  …õ, iter_limit , True, max_L_gradient_norm, False, False)
    # adaptive : true
    # weight in grad : false
    last_param_2, graph2 = sga_kullback_leibler_likelihood(f_target, q_init, nb_drawn_samples, nb_stochastic_choice, step,  None, …õ, iter_limit , True, max_L_gradient_norm, True, False)
    # adaptive : true
    # weight in grad : true
    last_param_3, graph3 =sga_kullback_leibler_likelihood(f_target, q_init, nb_drawn_samples, nb_stochastic_choice, step,  None, …õ, iter_limit , True, max_L_gradient_norm, True, True)
    
    last_theta_dict = {
        "IS q0": last_param_1,
        "IS qt": last_param_2,
        "œâ in grad":last_param_3
    }
    
    graph_dict = {
        "IS q0": graph1,
        "IS qt": graph2,
        "œâ in grad":graph3
    }
    
    color_dict = {
        "IS q0": "#227093",
        "IS qt": "#ff793f",
        "œâ in grad": "#218c74"
    }
    
    combine_error_graph(last_theta_dict, f_target.parameters_list(), q_init.parameters_list(), graph_dict, color_dict, nb_drawn_samples, nb_stochastic_choice, step, max_L_gradient_norm)


